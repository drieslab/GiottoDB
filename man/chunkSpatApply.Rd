% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/spatial_chunking.R
\name{chunkSpatApply}
\alias{chunkSpatApply}
\title{Apply a function in a spatially chunked manner}
\usage{
chunkSpatApply(
  x,
  y = NULL,
  chunk_y = TRUE,
  fun,
  extent = NULL,
  n_per_chunk = getOption("gdb.nperchunk", 1e+05),
  remote_name = result_count(),
  progress = TRUE,
  ...
)
}
\arguments{
\item{x}{dbPolygonProxy or dbPointsProxy}

\item{y}{dbPolygonProxy or dbPointsProxy (missing/NULL if not needed)}

\item{chunk_y}{(default = TRUE) whether y also needs to be spatially chunked
if it is provided.}

\item{fun}{function to apply. The only param(s) that 'fun' should
have are x and (optionally) y, based on the inputs to `chunkSpatApply.`}

\item{extent}{(optional) spatial extent to chunk across. Takes the extent of
\code{x} by default}

\item{n_per_chunk}{(default is 1e5) desired max number of records to process
per chunk. This value can be set using setting \code{options(gdb.nperchunk = ?)}}

\item{remote_name}{name to assign the result in the database. Defaults to a}

\item{progress}{whether to plot the progress
generic incrementing 'gdb_nnn' if not given}

\item{...}{additional params to pass to [dbvect]}
}
\value{
dbPolygonProxy or dbPointsProxy
}
\description{
Split a function operation into multiple spatial chunks. Results are appended
back into the database as a new table. This is not parallelized as some databases
do not work with parallel writes, but are more performant with large single
chunks of data. The functions that are provided, however, can be parallelized
in their processing after the chunk has been pulled into memory and only needs
to be combined into one before being written.
}
