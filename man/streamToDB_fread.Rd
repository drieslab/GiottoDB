% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/data_input.R
\name{streamToDB_fread}
\alias{streamToDB_fread}
\title{Stream large flat files to database backend using fread}
\usage{
streamToDB_fread(
  path,
  backend_ID,
  remote_name = "test",
  indices = NULL,
  nlines = 10000L,
  cores = 1L,
  callback = NULL,
  overwrite = FALSE,
  custom_table_fields = NULL,
  ...
)
}
\arguments{
\item{path}{path to the matrix file}

\item{backend_ID}{ID of the backend to use}

\item{remote_name}{name to assign table of read in values in database}

\item{indices}{(optional) if provided, specified columns (after all callbacks
complete) will have dictionaries generated, meaning a separate character vector
will be created holding only the unique values, where the ordering of this vector
is the mapped representative integer within the database table. These character
vectors are invisibly returned as a named list.}

\item{nlines}{integer. Number of lines to read per chunk}

\item{cores}{fread cores to use}

\item{callback}{callback functions to apply to each data chunk before it is
sent to the database backend}

\item{overwrite}{whether to overwrite if table already exists (default = FALSE)}

\item{custom_table_fields}{default = NULL. If desired, custom setup the fields
of the table. See \code{\link[DBI]{dbCreateTable}}}

\item{...}{additional params to pass to fread}
}
\description{
Files are read in chunks of lines via \code{fread} and then converted to the
required formatting with plugin functions provided through the \code{callback}
param before being written/appended to the database table.
This is slower than directly writing the information in, but is a scalable
approach as it never requires the full dataset to be in memory. \cr
If more than one or a custom callback is needed for the formatting then a
combined or new function can be defined on the spot as long as it accepts
\code{data.table} input and returns a \code{data.table}.
}
